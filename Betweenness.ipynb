{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marinaceccon1/LearningFromNetworksProject/blob/main/Betweenness.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computation with the second approach and the betweenness centrality"
      ],
      "metadata": {
        "id": "AIv6Dfg9ikBC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0czAGUzP9v1u"
      },
      "outputs": [],
      "source": [
        "#import the libraries needed\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import sys\n",
        "import collections\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clone the github repository containing the dataset\n",
        "!git clone https://github.com/marinaceccon1/LearningFromNetworksProject.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnxdGS1o-gwo",
        "outputId": "5642c1f2-9f11-4464-e721-ed081ce1e7e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LearningFromNetworksProject'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 36 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (36/36), 6.20 MiB | 2.45 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data and create the graph representing the network\n",
        "matrix = np.loadtxt('/content/LearningFromNetworksProject/out.txt', usecols=range(2))\n",
        "G = nx.from_edgelist(matrix)"
      ],
      "metadata": {
        "id": "WlLdhwLE-ozz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computes the local clustering coefficient and order the dictionaries w.r.t. the keys\n",
        "lcc = nx.clustering(G)\n",
        "ordered_lcc = collections.OrderedDict(sorted(lcc.items()))"
      ],
      "metadata": {
        "id": "RpTewNZ6_B4J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the betweenness centrality values from the bet.txt file"
      ],
      "metadata": {
        "id": "6I3OnTteMYtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file with 'read' mode\n",
        "f = open('/content/LearningFromNetworksProject/bet.txt', 'r')\n",
        "\n",
        "# Read all lines in the file\n",
        "lines = f.readlines()\n",
        "\n",
        "# Close the file\n",
        "f.close()\n",
        "\n",
        "# Create an empty list\n",
        "bet_centralities = []\n",
        "\n",
        "# Iterate over the lines and append the values to the list\n",
        "for line in lines:\n",
        "  bet_centralities.append(float(line))"
      ],
      "metadata": {
        "id": "VjutyFqM_FiB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a dictionary from the list bet_centralities\n",
        "# the keys of the dictionary are the node indices, the values is the betweenness centrality associated to that node\n",
        "bet_centr = {}\n",
        "for i in range(len(bet_centralities)):\n",
        "  bet_centr[i+1] = bet_centralities[i]"
      ],
      "metadata": {
        "id": "w6d4a6TeDhGp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sort the dictionary in increasing order w.r.t. the values (reserve = False)\n",
        "sorted_lcc = sorted(ordered_lcc.items(), key=lambda x:x[1], reverse = False)"
      ],
      "metadata": {
        "id": "Z1pkQTzC_bnv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save in len_sorted_lcc the number of values below the threshold\n",
        "for i in range(len(sorted_lcc)):\n",
        "  if sorted_lcc[i][1] > 0.24:\n",
        "    len_sorted_lcc = i\n",
        "    break"
      ],
      "metadata": {
        "id": "4PbrXIZbAHlV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sort the dictionary in decreasing order w.r.t. the values(reverse = True)\n",
        "sorted_bet_centr = sorted(bet_centr.items(),  key=lambda x:x[1], reverse = True)"
      ],
      "metadata": {
        "id": "W3lliMn6BFEP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save in len_sorted_bet_centr the number of values above the threshold\n",
        "for i in range(len(sorted_bet_centr)):\n",
        "  if sorted_bet_centr[i][1] < 0.95:\n",
        "    len_sorted_bet_centr = i\n",
        "    break"
      ],
      "metadata": {
        "id": "mDGSmqZ8DBdX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creates a list with the first len_sorted_lcc keys in the sorted_lcc list\n",
        "new_sorted_lcc = []\n",
        "for i in range(len_sorted_lcc):\n",
        "  new_sorted_lcc.append(sorted_lcc[i][0])\n",
        "s1 = set(new_sorted_lcc) #converts the list into a set, s1 eventually contains the indices of the nodes below the threshold"
      ],
      "metadata": {
        "id": "pjMs35tcHOTq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creates a list wit the first len_sorted_bet_centr keys in new_sorted_bet_centr\n",
        "new_sorted_bet_centr = []\n",
        "for i in range(len_sorted_bet_centr):\n",
        "  new_sorted_bet_centr.append(sorted_bet_centr[i][0])\n",
        "s2 = set(new_sorted_bet_centr) #converts the list into a set, s2 eventually contains the indices of the nodes above the threshold"
      ],
      "metadata": {
        "id": "2nYQkwjGHqHz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computes the intersection\n",
        "s = s1 & s2"
      ],
      "metadata": {
        "id": "5S7zQBdgINk0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_list = list(s)"
      ],
      "metadata": {
        "id": "D0V_ELJ2OKdM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cardinalities = {} #new dictionary, the keys will be pairs of nodes that are not adjacent, the value is the cardinality \n",
        "#of the intersection of their neighbourhoods\n",
        "\n",
        "for i in range(len(node_list)): #we consider all the nodes in this list, i.e. all the nodes with associated metrics within the thresholds\n",
        "  for j in range(i+1,len(node_list)): #in order not to contemplate the same pair twice, first as (i,j) and after as (j,i), we set j>i\n",
        "    \n",
        "    breakout_flag = False #needed to compute a double break\n",
        "    for key,value in (G.adj[node_list[i]]).items(): #check the neighbours of node_list[i]     \n",
        "      if key == node_list[j]: #if node_list[j] is a neighbour of node_list[i]\n",
        "        breakout_flag = True\n",
        "        break #exit the for key,value loop\n",
        "    if breakout_flag:\n",
        "      break #exit the for j loop\n",
        "\n",
        "    s1 = set(G.adj[node_list[i]]) #convert the dictionary in a set containing all the keys in the dictionary\n",
        "    s2 = set(G.adj[node_list[j]])\n",
        "    res = s1 & s2 #keys that belong to both sets\n",
        "\n",
        "    cardinalities[(node_list[i], node_list[j])] = len(res) #the value associated to that pair \n",
        "    #of nodes is the cardinality of the intersection computed above\n",
        "\n",
        "inverse_sorted_card = sorted(cardinalities.items(), key=lambda x:x[1], reverse = True) #order the dictionary by value (decreasing order)"
      ],
      "metadata": {
        "id": "4Ns8C2HHOXqV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 500"
      ],
      "metadata": {
        "id": "b0ToCMtgRsxP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add the firt N edges of inverse_sorted_card to a copy of G\n",
        "from builtins import sum as siumm\n",
        "\n",
        "G_1 = G.copy()\n",
        "for i in range(N):\n",
        "  u = inverse_sorted_card[i][0][0]\n",
        "  v = inverse_sorted_card[i][0][1]\n",
        "  G_1.add_edge(u,v)\n",
        "\n",
        "glo_clu_coeff = nx.transitivity(G_1) #compute the global clustering coefficient of the new graph\n",
        "triangles = siumm(nx.triangles(G_1).values())/3 #compute the number of triangles of the new graph\n",
        "print(glo_clu_coeff) \n",
        "print(triangles)"
      ],
      "metadata": {
        "id": "gHi1N_xzSaXm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}