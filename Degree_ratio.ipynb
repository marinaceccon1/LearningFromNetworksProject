{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marinaceccon1/LearningFromNetworksProject/blob/main/Degree_ratio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computation of the first approach with the degree centrality"
      ],
      "metadata": {
        "id": "x1s8HH5pt1U5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLnJ1c2S0GyA"
      },
      "outputs": [],
      "source": [
        "#import of the needed libraries\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import sys\n",
        "import collections\n",
        "from builtins import sum as siumm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clone the github repository containing the dataset\n",
        "!git clone https://github.com/marinaceccon1/LearningFromNetworksProject.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Baozwbsj0NMo",
        "outputId": "618f9f0d-486f-4b2b-9cb0-41a45b9f90d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LearningFromNetworksProject'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 18 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), 6.19 MiB | 2.51 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parameter K for the K nodes with the correct ratio centr/lcc\n",
        "K = 12000"
      ],
      "metadata": {
        "id": "rFpFbp0T0Nas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data and create the graph representing the network\n",
        "matrix = np.loadtxt('/content/LearningFromNetworksProject/out.txt', usecols=range(2))\n",
        "G = nx.from_edgelist(matrix)"
      ],
      "metadata": {
        "id": "v5aZqxFp0Ndm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computes the degree centrality and order the dictionary w.r.t. the keys\n",
        "deg_centralities = nx.degree_centrality(G)\n",
        "ordered_deg_centralities = collections.OrderedDict(sorted(deg_centralities.items()))"
      ],
      "metadata": {
        "id": "FDMQkTfM0Ngy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computes the local clustering coefficient and order the dictionary w.r.t. the keys\n",
        "lcc = nx.clustering(G)\n",
        "ordered_lcc = collections.OrderedDict(sorted(lcc.items()))"
      ],
      "metadata": {
        "id": "LGeaSYad0NkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a softmax function\n",
        "def softmax(vector):\n",
        "\te = np.exp(vector)\n",
        "\treturn e / e.sum()"
      ],
      "metadata": {
        "id": "7o1kU9GX0Nol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the values of degree centrality in the dictionary and insert them in a list \n",
        "ordered_deg_centr_values = list(ordered_deg_centralities.values())\n",
        "\n",
        "# extract the values of local clustering coefficient in the dictionary and insert them in a list \n",
        "# replace the vector with its softmax in order to avoid zero values\n",
        "ordered_lcc_values = softmax(list(ordered_lcc.values())) "
      ],
      "metadata": {
        "id": "AVNdCX990NsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if everything is ok\n",
        "assert[len(ordered_deg_centr_values)==len(ordered_lcc_values)]\n",
        "\n",
        "ratios = {} #new dictionary containing as value deg_centr/lcc\n",
        "\n",
        "for i in range(len(ordered_deg_centr_values)):\n",
        "  ratios[i+1] = (ordered_deg_centr_values[i]/ordered_lcc_values[i]) #the keys in the dictionaries start from 1, the indices in the lists start from 0\n",
        "\n",
        "# sort the dictionary by value, since reverse is equal to True, sort them in decreasing order\n",
        "# in this way the first K nodes are the one we are interested in\n",
        "sorted_ratios = sorted(ratios.items(), key=lambda x:x[1], reverse = True) \n",
        "\n",
        "# the output of the above function is a list of pairs of numbers, in each pair the first number represents \n",
        "# the key of the node, the second number is its value ratio = deg_centr/lcc\n",
        "# to access the key of the i-th pair the necessary command is sorted_ratio[i][0]"
      ],
      "metadata": {
        "id": "p2vuSlf40Nw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sorted_ratios is a list of pairs of numbers, in each pair the first number represents the key of the node, \n",
        "#the second number is its value ratio = deg_centr/lcc\n",
        "#to access the key of the i-th pair the necessary command is sorted_ratios[i][0]\n",
        "\n",
        "cardinalities = {} #new dictionary, the keys will be pairs of nodes that are not adjacent, the value is the cardinality \n",
        "#of the intersection of their neighbourhoods\n",
        "\n",
        "for i in range(K): #approximation: we only consider the K nodes with highest ratio\n",
        "  for j in range(i+1,K): #in order not to contemplate the same pair twice, first as (i,j) and after as (j,i), we set j>i\n",
        "    \n",
        "    breakout_flag = False #needed to compute a double break\n",
        "    for key,value in (G.adj[sorted_ratios[i][0]]).items(): #check the neighbours of sorted_ratios[i][0]      \n",
        "      if key == sorted_ratios[j][0]: #if inverse_sorted_ratio[j][0] is a neighbour of sorted_ratios[i][0]\n",
        "        breakout_flag = True\n",
        "        break #exit the for key,value loop\n",
        "    if breakout_flag:\n",
        "      break #exit the for j loop\n",
        "\n",
        "    s1 = set(G.adj[sorted_ratios[i][0]]) #convert the dictionary in a set containing all the keys in the dictionary\n",
        "    s2 = set(G.adj[sorted_ratios[j][0]])\n",
        "    res = s1 & s2 #keys that belong to both sets\n",
        "\n",
        "    cardinalities[(sorted_ratios[i][0], sorted_ratios[j][0])] = len(res) #the value associated to that pair \n",
        "    #of nodes is the cardinality of the intersection computed above\n",
        "\n",
        "inverse_sorted_card = sorted(cardinalities.items(), key=lambda x:x[1], reverse = True) #order the dictionary by value"
      ],
      "metadata": {
        "id": "YaKRR79M0N1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 500"
      ],
      "metadata": {
        "id": "wkpCHShl0N49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_i_deg = G.copy()"
      ],
      "metadata": {
        "id": "79OeWYzr0N9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from builtins import sum as siumm\n",
        "#add the first N edges of inverse_sorted_card\n",
        "for i in range(N):\n",
        "  u_deg = inverse_sorted_card[i][0][0]\n",
        "  v_deg = inverse_sorted_card[i][0][1]\n",
        "  G_i_deg.add_edge(u_deg,v_deg)\n",
        "\n",
        "glo_clu_coeff_deg = nx.transitivity(G_i_deg) #compute the global clustering coefficient of the new graph\n",
        "print(glo_clu_coeff_deg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcQClcOu0OGg",
        "outputId": "0d4fc88b-dff4-492b-cc9a-1fc167294bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14818319804572128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "triangles_tot = siumm(nx.triangles(G_i_deg).values()) #compute the number of triangles of the new graph\n",
        "print(triangles_tot/3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Su7yKlZ0OJk",
        "outputId": "4de6ceb4-14ec-4991-bb3d-e8eb6c37d442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3521374.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computation of the number of triangles after adding N random edges to G"
      ],
      "metadata": {
        "id": "uiPEQUfsut3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from builtins import sum as siumm\n",
        "\n",
        "N=500\n",
        "glo_clu=[]\n",
        "triangles = []\n",
        "#average 10 clustering coefficents you get by adding N random edges \n",
        "for i in range(10):\n",
        "  G_i = G.copy()\n",
        "  j = 1\n",
        "  while j <= N:\n",
        "    u = random.randint(1,G.number_of_nodes())\n",
        "    v = random.randint(1,G.number_of_nodes())\n",
        "    if not G_i.has_edge(u, v):\n",
        "      G_i.add_edge(u,v)\n",
        "      j+=1\n",
        "  triangle = siumm(nx.triangles(G_i).values())/3\n",
        "  triangles.append(triangle)\n",
        "avg_triangl = sum(triangles)/len(triangles)"
      ],
      "metadata": {
        "id": "PL8EmytwrBhJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}